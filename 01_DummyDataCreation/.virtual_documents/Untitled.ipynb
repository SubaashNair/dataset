# ! pip3 install faker


# import pandas as pd
# import numpy as np
# from faker import Faker

# # Initialize Faker
# fake = Faker()

# # Set random seed for reproducibility
# np.random.seed(0)

# # Number of rows in the dataset
# num_rows = 100000

# # Create an empty DataFrame
# data = pd.DataFrame({
#     'Sales_ID': [fake.uuid4() for _ in range(num_rows)],
#     'Product_Category': [fake.word() for _ in range(num_rows)],
#     'Sales_Amount': np.round(np.random.uniform(100, 1000, num_rows), 2),
#     'Discount': np.round(np.random.uniform(0, 50, num_rows), 2),
#     'Sales_Region': [fake.city() for _ in range(num_rows)],
#     'Date_of_Sale': [fake.date_this_year() for _ in range(num_rows)],
#     'Customer_Age': np.random.randint(18, 70, num_rows),
#     'Customer_Gender': [np.random.choice(['Male', 'Female', 'Other']) for _ in range(num_rows)],
#     'Sales_Representative': [fake.name() for _ in range(num_rows)]
# })

# # Introduce null values
# null_indices = np.random.choice(num_rows, size=int(num_rows * 0.1), replace=False)  # 10% null values

# # Randomly set some entries to NaN
# for col in ['Sales_Amount', 'Discount', 'Customer_Age', 'Customer_Gender']:
#     data.loc[null_indices, col] = np.nan

# # Display the DataFrame
# # print(data.head())
# data.to_csv('sales.csv')


import pandas as pd
import numpy as np
from faker import Faker

# Initialize Faker
fake = Faker()

# Set random seed for reproducibility
np.random.seed(0)

# Number of rows in the dataset
num_rows = 100000

# Expanded list of product categories
product_categories = [
    'Electronics', 'Clothing', 'Home & Kitchen', 'Books', 'Toys', 'Sports', 'Beauty', 'Automotive',
    'Garden', 'Office Supplies', 'Health', 'Jewelry', 'Movies', 'Music', 'Software', 'Pet Supplies',
    'Furniture', 'Appliances', 'Groceries', 'DIY', 'Personal Care', 'Outdoor', 'Baby Products', 'Tools'
]

# Create an empty DataFrame
data = pd.DataFrame({
    'Sales_ID': [fake.uuid4() for _ in range(num_rows)],
    'Product_Category': np.random.choice(product_categories, num_rows),
    'Sales_Amount': np.round(np.random.uniform(100, 1000, num_rows), 2),
    'Discount': np.round(np.random.uniform(0, 50, num_rows), 2),
    'Sales_Region': [fake.city() for _ in range(num_rows)],
    'Date_of_Sale': [fake.date_this_year() for _ in range(num_rows)],
    'Customer_Age': np.random.randint(18, 70, num_rows),
    'Customer_Gender': [np.random.choice(['Male', 'Female', 'Other']) for _ in range(num_rows)],
    'Sales_Representative': [fake.name() for _ in range(num_rows)]
})

# Introduce null values
null_indices = np.random.choice(num_rows, size=int(num_rows * 0.1), replace=False)  # 10% null values

# Randomly set some entries to NaN
for col in ['Sales_Amount', 'Discount', 'Customer_Age', 'Customer_Gender']:
    data.loc[null_indices, col] = np.nan

# Display the DataFrame
# print(data.head())
data.to_csv('sales_100k.csv')



